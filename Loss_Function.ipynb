{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JL9b6zUNRdj",
        "outputId": "44f6de06-2574-44ca-85eb-18a6b7735ca9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 8.8572\n",
            "Epoch 100, Loss: 0.0138\n",
            "Epoch 200, Loss: 0.0063\n",
            "Epoch 300, Loss: 0.0028\n",
            "Epoch 400, Loss: 0.0013\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# ReLU activation\n",
        "def relu(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "def relu_derivative(x):\n",
        "    return (x > 0).astype(float)\n",
        "\n",
        "# Huber loss\n",
        "def huber_loss(y_true, y_pred, delta=1.0):\n",
        "    error = y_true - y_pred\n",
        "    loss = np.where(np.abs(error) <= delta,\n",
        "                    0.5 * error**2,\n",
        "                    delta * (np.abs(error) - 0.5 * delta))\n",
        "    return np.mean(loss)\n",
        "\n",
        "# Sample data\n",
        "X = np.array([[1], [2], [3], [4]], dtype=float)\n",
        "y = np.array([[2], [4], [6], [8]], dtype=float)\n",
        "\n",
        "# Initialize weights\n",
        "np.random.seed(1)\n",
        "W1 = np.random.randn(1, 3)\n",
        "b1 = np.zeros((1, 3))\n",
        "W2 = np.random.randn(3, 1)\n",
        "b2 = np.zeros((1, 1))\n",
        "\n",
        "lr = 0.01 # Training loop\n",
        "for epoch in range(500):\n",
        "    # Forward pass\n",
        "    z1 = X @ W1 + b1\n",
        "    a1 = relu(z1)\n",
        "    y_pred = a1 @ W2 + b2\n",
        "\n",
        "    # Loss\n",
        "    loss = huber_loss(y, y_pred)\n",
        "\n",
        "    # Backpropagation\n",
        "    error = y_pred - y\n",
        "    dW2 = a1.T @ error / len(X)\n",
        "    db2 = np.mean(error, axis=0, keepdims=True)\n",
        "\n",
        "    da1 = error @ W2.T\n",
        "    dz1 = da1 * relu_derivative(z1)\n",
        "    dW1 = X.T @ dz1 / len(X)\n",
        "    db1 = np.mean(dz1, axis=0, keepdims=True)\n",
        "\n",
        "    # Update weights\n",
        "    W1 -= lr * dW1\n",
        "    b1 -= lr * db1\n",
        "    W2 -= lr * dW2\n",
        "    b2 -= lr * db2\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {loss:.4f}\")"
      ]
    }
  ]
}